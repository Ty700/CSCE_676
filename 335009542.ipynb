{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ty700/CSCE_676/blob/main/335009542.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak3SqhmRDYKW"
      },
      "source": [
        "## CSCE 676 :: Data Mining and Analysis :: Texas A&M University :: Spring 2026\n",
        "\n",
        "\n",
        "# Weekly Homework 1: Data Basics\n",
        "\n",
        "\n",
        "***Goals of this homework:***\n",
        "Onboard into the course (introductions and short video), perform end-to-end data analysis on a noisy real-world dataset (ingestion, cleaning, feature engineering, and exploratory data analysis), practice clear technical communication (written and spoken via short video), and answer interview-style questions that assess data reasoning, assumptions, tradeoffs, and limitations.\n",
        "\n",
        "\n",
        "***Submission instructions:***\n",
        "\n",
        "You should post your notebook to Canvas (look for the homework 1 assignment there). Please name your submission **your-uin_hw1.ipynb**, so for example, my submission would be something like **555001234_hw1.ipynb**. Your notebook should be fully executed when you submit ... so run all the cells for us so we can see the output, then submit that.\n",
        "\n",
        "***Grading philosophy:***\n",
        "\n",
        "We are grading reasoning, judgment, and clarity, not just correctness. Show us that you understand the data, the constraints, and the limits of your conclusions.\n",
        "\n",
        "***For each question, you need to respond with 3 cells:***\n",
        "1. **[A Code Cell] Your Code:** If code is not applicable, put `# no code` in the cell. For tests: tests can be simple assertions or checks (e.g., using `assert` or `print` or small functions or visual inspection); formal testing frameworks are not required.\n",
        "2. **[A Markdown Cell] Your Answer:** Write up your answers and explain them in complete sentences. Include any videos in this section as well; for videos, upload them to your TAMU Google Drive, and ensure they are set to be visible by the instruction team (`caverlee@tamu.edu` and `mariateleki@tamu.edu`), then share the link to the video in the cell.\n",
        "3. **[A Markdown Cell] Your Resources:** You need to cite 3 types of resources and note how they helped you: (1) Collaborators, (2) Web Sources (e.g. StackOverflow), and (3) AI Tools (you must also describe how you prompted, but we do not require any links to any specific chats). Specifically, use the following format as a template:\n",
        "```\n",
        "On my honor, I declare the following resources:\n",
        "1. Collaborators:\n",
        "- Reveille A.: Helped me understand that a df in pandas is a data structure kinda like a CSV.\n",
        "- Sully A.: Helped me fix a bug with the vector addition of 2 columns.\n",
        "- ...\n",
        "\n",
        "2. Web Sources:\n",
        "- https://stackoverflow.com/questions/46562479/python-pandas-data-frame-creation: how to create a pd df\n",
        "- ...\n",
        "\n",
        "3. AI Tools:\n",
        "- ChatGPT: I gave it the homework .ipynb file and the ufo.csv, and told it to generate the code for the first question, but it did it with csv.reader(), so I re-prompted it to use pandas and that one was correct\n",
        "- ...\n",
        "```\n",
        "***Why do we require this cell?*** This cell is important...\n",
        "\n",
        "1. For academic integrity, you must give credit where credit is due.\n",
        "\n",
        "2. We want you to pay attention to how you can successfully get help to move through problems! Is there someone you work with or an AI tool that helps you learn the material better? That's great! The point of engineering is to use your tools to solve hard problems, and part of graduate school is learning about how *you* learn and solve problems best.\n",
        "\n",
        "***A reminder: you get out of it what you put into it.***\n",
        "Do your best on these homeworks, show us your creativity, and ask for help when you need it -- good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMdE62rNxpFl"
      },
      "source": [
        "# A [4pts]. Hi! Introduce Yourself\n",
        "\n",
        "**Note:** We only need 1 markdown cell for these questions.\n",
        "\n",
        "**Rubric**\n",
        "\n",
        "[2pt] Complete, thoughtful response.\n",
        "\n",
        "[1pt] Partial response.\n",
        "\n",
        "[0pt] Minimal response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yqxVFSIyQCS"
      },
      "source": [
        "## 1.\n",
        "Welcome to CSCE 676! Head to this thread -- **\"Week 1: Introductions (on Canvas Discussions)\"** -- in this week's module and introduce yourself. When you're done, type \"done\" here.\n",
        "**Done.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGSP2TqRyP70"
      },
      "source": [
        "## 2.\n",
        "\n",
        "I want to get to know you all! Please share a very brief (1min max) video saying hello.\n",
        "\n",
        "What to include:\n",
        "\n",
        "* A greeting (hello, hola, yo!, whatever)\n",
        "* Please tell me how you pronounce your name\n",
        "* One memorable thing -- could be your favorite meme, an interesting fact, favorite movie, etc. Just something that will help me remember -- like \"Aha, Alice is that student who really loves skateboarding\".\n",
        "\n",
        "See the introduction for instructions on how to share the video.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e71ce5f"
      },
      "source": [
        "\n",
        "# B [64pts]. UFO Sightings — Data Ingestion, Cleaning, and Feature Engineering\n",
        "\n",
        "**Dataset:** `ufos.csv`\n",
        "\n",
        "Detected columns: `datetime`, `city`, `state`, `country`, `shape`, `duration (seconds)`, `duration (hours/min)`, `comments`, `date posted`, `latitude`, `longitude`, and possibly extra unnamed columns.\n",
        "\n",
        "**Goal:** Perform a set of tasks to load the data, diagnose issues, clean/standardize it, and derive basic features to support downstream mining using the Python package `pandas`.\n",
        "\n",
        "**Rubric**\n",
        "\n",
        "[8 pts] Strong/Professional: Correct and complete implementation of the task; Reasonable assumptions, stated or implied, and justified; Thoughtful handling of real-world data issues (missingness, noise, scale, duplicates, edge cases); Clear, concise explanations of what was done and why; Code is clean, readable, and well-structured, uses appropriate pandas, and would plausibly pass a professional code review; Tests meaningfully validate non-trivial behavior (not just \"the code runs so it must be right\").\n",
        "\n",
        "[4 pts] Partial/Developing: Core task mostly completed but with gaps, weak assumptions, or minor mistakes; Reasoning is shallow or mostly descriptive; Code works but is messy, repetitive, or fragile; Tests are superficial, incomplete, or poorly motivated.\n",
        "\n",
        "[0 pts] Minimal/Incorrect: Task is largely incorrect, missing, or misunderstands the goal; Little to no reasoning or justification; Code does not run or ignores constraints; No meaningful tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a097fc3"
      },
      "source": [
        "\n",
        "## 1.\n",
        "\n",
        "* Load `ufos.csv` into a pd.DataFrame named `ufo_raw`.\n",
        "* Display 5 random rows and `ufo_raw.info()`.\n",
        "* Display the number of rows/columns.\n",
        "* Display any empty columns.\n",
        "* Write at least 1 test for your code, then answer: What did you test for? How do you know your code is correct?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOxzt3m0c_wO",
        "outputId": "7365e254-0926-456e-ee27-701e5123aee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================== RANDOM 5 ROWS ========================\n",
            "              datetime         city state country  shape duration (seconds)  \\\n",
            "36881  3/24/2004 02:00     moorpark    ca      us  light                  5   \n",
            "68504   7/4/2004 23:00  casselberry    fl      us  light                180   \n",
            "32422   2/4/2001 20:00        amity    or      us   disk                  7   \n",
            "28149   1/9/2008 19:00  san antonio    tx      us   disk                  2   \n",
            "53019   6/1/2006 19:15        ogden    ut      us    egg                600   \n",
            "\n",
            "      duration (hours/min)                                           comments  \\\n",
            "36881            5 seconds  At night&#44looking out window.  All of a sudd...   \n",
            "68504            3 minutes     Large flash huge boom NASA vehicles everywhere   \n",
            "32422                hours  PLEASE HELP US FIND OUT WHAT WE ARE SEEING IN ...   \n",
            "28149              seconds  ((HOAX??))  Saw a 40 long by 12 ft tall saucer...   \n",
            "53019              10 min.  It moved slowly&#44 was very very high&#44 and...   \n",
            "\n",
            "      date posted    latitude   longitude  \n",
            "36881   3/28/2004  34.2855556 -118.881111  \n",
            "68504   7/25/2004  28.6775000  -81.328056  \n",
            "32422   2/18/2001  45.1158333 -123.206111  \n",
            "28149   2/14/2008  29.4238889  -98.493333  \n",
            "53019   7/16/2006  41.2230556 -111.973056  \n",
            "\n",
            "======================== UFO_RAW.INFO() ========================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 88679 entries, 0 to 88678\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   datetime              88679 non-null  object \n",
            " 1   city                  88679 non-null  object \n",
            " 2   state                 81270 non-null  object \n",
            " 3   country               76314 non-null  object \n",
            " 4   shape                 85757 non-null  object \n",
            " 5   duration (seconds)    88677 non-null  object \n",
            " 6   duration (hours/min)  85660 non-null  object \n",
            " 7   comments              88644 non-null  object \n",
            " 8   date posted           88679 non-null  object \n",
            " 9   latitude              88679 non-null  object \n",
            " 10  longitude             88679 non-null  float64\n",
            "dtypes: float64(1), object(10)\n",
            "memory usage: 7.4+ MB\n",
            "None\n",
            "\n",
            "======================== UFO_RAW ROWS & COLUMNS ========================\n",
            "UFO ROWS: 88679\n",
            "UFO COLUMNS: 11\n",
            "\n",
            "======================== UFO_RAW EMPTY COLUMNS ========================\n",
            "No empty columns\n",
            "\n",
            "======================== UFO_RAW BAD LINES ========================\n",
            "Bad lines: 196\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "bad_lines = []\n",
        "ufo_raw = pd.read_csv('ufos.csv', engine='python', on_bad_lines=lambda line: bad_lines.append(line))\n",
        "\n",
        "# Tests to make sure ufos.csv was loaded correctly\n",
        "assert(ufo_raw.shape[0] > 0)\n",
        "assert(ufo_raw.shape[1] > 0)\n",
        "\n",
        "# Test to make sure ufo_raw is of DataFrame type\n",
        "assert(type(ufo_raw) == pd.core.frame.DataFrame)\n",
        "\n",
        "# Displays a random 5 rows\n",
        "print(\"======================== RANDOM 5 ROWS ========================\")\n",
        "print(ufo_raw.sample(5), end='\\n\\n')\n",
        "\n",
        "# Displays information about ufo_raw CSV\n",
        "print(\"======================== UFO_RAW.INFO() ========================\")\n",
        "print(ufo_raw.info(), end='\\n\\n')\n",
        "\n",
        "print(\"======================== UFO_RAW ROWS & COLUMNS ========================\")\n",
        "print(f\"UFO ROWS: {ufo_raw.shape[0]}\")\n",
        "print(f\"UFO COLUMNS: {ufo_raw.shape[1]}\", end='\\n\\n')\n",
        "\n",
        "print(\"======================== UFO_RAW EMPTY COLUMNS ========================\")\n",
        "# Finds all empty columns\n",
        "empty_columns = [col for col in ufo_raw.columns if ufo_raw[col].isna().all()]\n",
        "if empty_columns:\n",
        "    print('\\n'.join(empty_columns))\n",
        "    print('\\n\\n')\n",
        "else:\n",
        "    print(\"No empty columns\\n\")\n",
        "\n",
        "print(\"======================== UFO_RAW BAD LINES ========================\")\n",
        "# Prints all bad lines\n",
        "if bad_lines:\n",
        "    print(f\"Bad lines: {len(bad_lines)}\")\n",
        "else:\n",
        "    print(\"No bad lines\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa5gnJlBk1_y"
      },
      "source": [
        "## Q/A\n",
        "\n",
        "### 1. What did you test for? How do you know your code is correct?\n",
        "\n",
        "I tested to make sure the ufos.csv data was read correctly by asserting the rows and columns were greather than 0.\n",
        "\n",
        "I also tested to make sure ufo_raw's data type was pd.DataFrame.\n",
        "\n",
        "```\n",
        "On my honor, I declare the following resources:\n",
        "1. Collaborators:\n",
        "N/A\n",
        "\n",
        "2. Web Sources:\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame: Used for understanding DataFrame APIs (read_csv, on_bad_lines, isna, etc)\n",
        "\n",
        "3. AI Tools:\n",
        "- Sonnet 4.5: I gave it the ufo.csv and prompted it to characterize the set. (How many columns are empty, bad lines, total rows/columns)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d30c61bd"
      },
      "source": [
        "\n",
        "## 2.\n",
        "\n",
        "Create a cleaned DataFrame `ufo`:\n",
        "\n",
        "* Drop fully-empty or irrelevant columns (e.g., unnamed columns).\n",
        "* Parse `datetime` to `datetime64[ns]` (`errors='coerce'`).\n",
        "* Coerce `duration (seconds)`, `latitude`, `longitude` to numeric.\n",
        "* Lowercase/trim `city`, `state`, `country`, `shape`.\n",
        "* Remove rows with impossible coordinates (lat ∉ [-90,90], lon ∉ [-180,180]).\n",
        "* Drop exact duplicates based on a reasonable subset (document your choice).\n",
        "* Write at least 2 tests for your code (focus on the most complicated parts), then answer: What did you test for? How do you know your code is correct?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUTGCyyT_SgK"
      },
      "outputs": [],
      "source": [
        "# Drop fully-empty or irrelevant columns\n",
        "ufo = ufo_raw.drop(columns=empty_columns, axis=1)\n",
        "\n",
        "# Parse datetime to datetime64[ns] (errors='coerce').\n",
        "ufo['datetime'] = pd.to_datetime(ufo['datetime'], errors='coerce')\n",
        "assert(ufo['datetime'].dtype == 'datetime64[ns]')\n",
        "\n",
        "# Coerce duration (seconds), latitude, longitude to numeric.\n",
        "ufo['duration (seconds)'] = pd.to_numeric(ufo['duration (seconds)'], errors='coerce')\n",
        "ufo['latitude'] = pd.to_numeric(ufo['latitude'], errors='coerce')\n",
        "ufo['longitude'] = pd.to_numeric(ufo['longitude'], errors='coerce')\n",
        "assert(ufo['duration (seconds)'].dtype == 'float64')\n",
        "assert(ufo['latitude'].dtype == 'float64')\n",
        "assert(ufo['longitude'].dtype == 'float64')\n",
        "\n",
        "# Lowercase/trim city, state, country, shape\n",
        "trim_cols = ['city', 'state', 'country', 'shape']\n",
        "for col in trim_cols:\n",
        "    ufo[col] = ufo[col].str.lower().str.strip()\n",
        "\n",
        "# Remove rows with impossible coordinates (lat ∉ [-90,90], lon ∉ [-180,180]).\n",
        "ufo = ufo[(ufo['latitude'] >= -90) & (ufo['latitude'] <= 90)]\n",
        "ufo = ufo[(ufo['longitude'] >= -180) & (ufo['longitude'] <= 180)]\n",
        "\n",
        "# Drop exact duplicates based on a reasonable subset (document your choice).\n",
        "before_drop = ufo.shape[0]\n",
        "ufo = ufo.drop_duplicates(subset=['datetime', 'city', 'state', 'country'])\n",
        "\n",
        "assert (((before_drop - ufo.shape[0])/before_drop) * 100) <= 30, \"More than 30% of entires dropped...\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ABpTafi_uvW"
      },
      "source": [
        "### Q/A\n",
        "1. What did you test for? How do you know your code is correct?\\\n",
        "    Assertions:\n",
        "    1. After converting ufo's column types, I made sure they were the type I was looking for.\n",
        "    2. I found that my subset to determine duplicates was aggressive at the beginning. I added an assertion to make sure that I wasn't being too aggressive.\n",
        "2. Why did I choose `['datetime', 'city', 'state', 'country']` as my subset to determine duplicates?\n",
        "\n",
        "    I determined that true duplicates should have the same location (city, state, country). However, I included datetime to preserve multiple independent sightings in the same location at different times.\n",
        "\n",
        "    This approach removes exact duplicate reports (same time and place) while keeping legitimate multiple sightings in the same city.\n",
        "\n",
        "    I am still trying to implement a ±1 hour time window to catch near-duplicate reports that might be the same event reported with slightly different timestamps.\n",
        "```\n",
        "On my honor, I declare the following resources:\n",
        "1. Collaborators:\n",
        "N/A\n",
        "\n",
        "2. Web Sources:\n",
        "- https://pandas.pydata.org/docs/reference/series.html: Used for understanding Pandas Series APIs (strip, lower, dtype)\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame: Used to understand drop and drop_duplicates\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html#pandas.to_numeric: Understanding the to_numeric method\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html#pandas.to_datetime: Understanding the to_datetime method\n",
        "\n",
        "3. AI Tools:\n",
        "- Sonnet 4.5: Used it to help with the last assertion by attaching message.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuJo3xz4_oFY"
      },
      "source": [
        "## 3.\n",
        "\n",
        "Now take a look at the `duration (hours/min)` column. For this question, we'd like you to just extract how ever many unique versions of durations reported in *minutes* you can from the `duration (hours/min)` column. In other words, find as many different variations of anything that could be reasonably interpreted as a minute-like duration. Examples include:\n",
        "* several minutes\n",
        "* x to y minutes\n",
        "* x minutes\n",
        "* x min.\n",
        "* x mins.\n",
        "* and so on ...\n",
        "\n",
        "Write at least 2 tests for your code (focus on the most complicated parts), then answer: What did you test for? How do you know your code is correct?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "852a5a98"
      },
      "source": [
        "\n",
        "## 4.\n",
        "\n",
        "Create additional columns in a new feature engineering version of the dataset called `ufo_fe`:\n",
        "\n",
        "- `year`, `month`, `hour` from `datetime`\n",
        "- `duration_log10` = log10(duration_seconds + 1)\n",
        "- `duration_bucket` = categorical bins for `duration (seconds)` (you may adjust edges)\n",
        "- `us_only` = 1 if `country == 'us'` else 0\n",
        "\n",
        "Then produce:\n",
        "- Value counts of `shape` (top 10).\n",
        "- A table of sightings by `year` (counts).\n",
        "- A `state × shape` table (top 10 states by sample size).\n",
        "- A matplotlib or seaborn visualization of the top 10 states by number of UFO sightings. Write about which visualization you selected, and why.\n",
        "- Write at least 2 tests for your code (focus on the most complicated parts), then answer: What did you test for? How do you know your code is correct?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7b29396"
      },
      "source": [
        "\n",
        "## 5.\n",
        "\n",
        "In 3–6 sentences, based on your previous answers, summarize data quality and distributional patterns; use at least 3 facts about the dataset produced by your analysis in the previous questions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HJ0A9uT4xco"
      },
      "source": [
        "# 6.\n",
        "* In a new chat, prompt an AI tool to perform an EDA on the dataset for you, e.g., *Here is my dataset (attached). Give python code for a basic EDA.* Paste and run the code here (re-prompt until it gives reasonable output if there are bugs/failures).\n",
        "* Write at least 2 tests for your code (focus on the most complicated parts), then answer: What did you test for? How do you know the code is correct?\n",
        "* So, what did ChatGPT do for the EDA?\n",
        "* Come up with 3 things it could've done instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSPV7ek85nXQ"
      },
      "source": [
        "# 7.\n",
        "* Now, give screenshots of your code output back to the AI tool, and ask it to interpret the results for you, e.g., *Here are the results, interpret.* Paste the interpretation it provides here.\n",
        "* What do you agree with?\n",
        "* What do you disagree with?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2e3e14"
      },
      "source": [
        "\n",
        "## 8.\n",
        "\n",
        "* Propose and implement 1-2 concrete next steps for your EDA (e.g., better deduplication with fuzzy text, geospatial clustering, normalization of duration text, timezone handling, creation of dummy variables, visualization of a different column, etc.) to improve your understanding of the data, pretending that you are going to use this dataset for important downstream tasks later.\n",
        "* Interpret your results: what did you learn about the dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5cqkoNzB27p"
      },
      "source": [
        "# C [30pts]. Interview Questions\n",
        "\n",
        "We now pretend this is a real job interview. Here's some guidance on how to answer these questions:\n",
        "\n",
        "1. Briefly restate the question and state any assumptions you are making.\n",
        "\n",
        "2. Explain your reasoning out loud, focusing on tradeoffs, limitations, and constraints.\n",
        "\n",
        "3. As a principle, keep your answers as short and clear as they can be (while still answering the question).\n",
        "\n",
        "4. Write/speak in a conversational but professional tone (avoid being overly formal). For speaking: speak at a reasonable pace and volume, speak clearly, pause when you need to, and practice making \"eye contact\" with the camera. Keep a confident, positive, and professional tone. *For additional coaching and practice, the University Writing Center provides individual appointments: https://writingcenter.tamu.edu/make-an-appointment.*\n",
        "\n",
        "There may not be a single correct answer. We are grading whether your reasoning is reasonable and aware of limitations.\n",
        "\n",
        "These questions are written unless a video response is specified.\n",
        "\n",
        "\n",
        "**Rubric**\n",
        "\n",
        "[6pt] Clear understanding of the question; reasonable assumptions; thoughtful reasoning that acknowledges tradeoffs and limitations; clear, concise communication in a conversational but professional tone (for speaking: clear pace, volume, and articulation).\n",
        "\n",
        "[3pt] Basic understanding but shallow reasoning or unclear assumptions; communication is somewhat unclear, overly verbose, or overly informal/formal.\n",
        "\n",
        "[0pt] Minimal, unclear, or incorrect response; poor communication or unprofessional tone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U42KuNOXzaGe"
      },
      "source": [
        "## 1.\n",
        "When should you use `pandas` versus just read in a csv?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYGKMuvvzs1h"
      },
      "source": [
        "## 2.\n",
        "If this dataset suddenly grew by 10000×, which parts of your analysis pipeline would fail first? (Hint: Consider your hardware constraints.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IChm84CBzs4S"
      },
      "source": [
        "## 3.\n",
        "Assume some fraction of reports are adversarially fabricated (meaning: someone submitted fake UFO reports on purpose). How does that change your analysis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D20KEwAi0CxL"
      },
      "source": [
        "## 4.\n",
        "How would incorrect timezone handling distort downstream statistical conclusions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEp7YYbn0C1z"
      },
      "source": [
        "## 5.\n",
        "Now, link to a video (1 min. max) of yourself answering the following question: What kind of selection bias do you think is present in this web-based UFO dataset?\n",
        "\n",
        "Make sure to end on a follow-up question for the interviewer -- e.g., *So, to get some more context, are you thinking about this for a Speech AI application like Siri?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BOimHuE4H7D"
      },
      "source": [
        "# D [2pts]. What new questions do you have?\n",
        "We want you to think bigger! Tell us what questions and curiosity this homework brings up for you.\n",
        "\n",
        "**Rubric**\n",
        "\n",
        "[2pt] Complete, thoughtful response.\n",
        "\n",
        "[1pt] Partial response.\n",
        "\n",
        "[0pt] Minimal response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1FQ3Cys4J2P"
      },
      "source": [
        "# 1.\n",
        "What new questions do you have about data cleaning and exploratory data analysis (in general) after this homework? Or, what topics are you curious about now? List at least 3."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}